{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BelRom/PythonHW3/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22Environment_example_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXXTuy_o0sjk",
    "outputId": "21fd2c3e-3743-473b-d02f-8ef436a54523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U kaggle_environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yz23vWHD0wcj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n",
      "No pygame installed, ignoring import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle_environments import make, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kuo6IOxiRub"
   },
   "source": [
    "Опишем поведение агента, всегда играющего \"камень\" - это значение 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqTqV7B92rJ6",
    "outputId": "31caf00b-0fbf-4d82-8104-d7bbbf25a56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rock_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_agent.py\n",
    "\n",
    "#Example of the simple agent\n",
    "#0 - rock\n",
    "#1 - paper\n",
    "#2 - scissors\n",
    "def your_agent(observation, configuration):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et1J5hUGigeh"
   },
   "source": [
    "Попробуем теперь использовать информацию о прошлых действиях противника. Опишем агента, который производит то же самое действие, что и оппонент на прошлом ходу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7l6Ttw6qi0jk",
    "outputId": "7a88254f-a866-4c5c-e334-2cf0e0503e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting copy_opponent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile copy_opponent.py\n",
    "\n",
    "#Example\n",
    "def copy_opponent(observation, configuration):\n",
    "    #in case we have information about opponent last move\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    #initial step\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExgIpXUVjbjN"
   },
   "source": [
    "Воспользуемся функцией evaluate из библиотеки kaggle_environments с помощью которой запустим наших агентов и проведем эксперимент на заданном количестве игр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Опишем поведение агента который всегда выбирает ножницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scissors_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scissors_agent.py\n",
    "\n",
    "#Example of the simple agent\n",
    "#0 - rock\n",
    "#1 - paper\n",
    "#2 - scissors\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Опишем поведение агента который всегда выбирает бумагу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting paper_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paper_agent.py\n",
    "\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Опишем поведение агента который чередует ножницы и камень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rock_scissors_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_scissors_agent.py\n",
    "\n",
    "def rock_scissors_agent(observation, configuration):\n",
    "    result = 0\n",
    "    if observation.step % 2 == 0:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = 2\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Опишем поведение агента который чередует камень и бумагу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rock_paper_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_paper_agent.py\n",
    "\n",
    "def rock_paper_agent(observation, configuration):\n",
    "    result = 0\n",
    "    if observation.step % 2 == 0:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Опишем поведение агента который последовательно выбирает камень, ножницы, бумагу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting order_rock_scissors_paper_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile order_rock_scissors_paper_agent.py\n",
    "\n",
    "def order_rock_scissors_paper_agent(observation, configuration):\n",
    "    result = 0\n",
    "    if observation.step % 3 == 0:\n",
    "        result = 0\n",
    "    if observation.step % 2 == 0:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Опишем поведение агента который случайно выбирает любой элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile random_agent.py\n",
    "\n",
    "import random\n",
    "\n",
    "def random_agent(observation, configuration):\n",
    "    return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 Опишем поведение агента который меняет действие на противоположное по отношению к опоненту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting oposite_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile oposite_agent.py\n",
    "\n",
    "def oposite_agent(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        return 2\n",
    "    if observation.lastOpponentAction == 0:\n",
    "        return 1\n",
    "    elif observation.lastOpponentAction == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Опишем поведение агента который сдвиг на 1 по отношению к прошлому действию опонента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting shift_one_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile shift_one_agent.py\n",
    "\n",
    "def shift_one_agent(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (observation.lastOpponentAction + 1) % 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 Опишем поведение агента который сдвиг на случайное число по отношению к прошлому действию опонента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting shift_random_agen\n"
     ]
    }
   ],
   "source": [
    "%%writefile shift_random_agen    \n",
    "import random\n",
    "\n",
    "def shift_random_agent(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (observation.lastOpponentAction + random.randrange(0, 100)) % 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Опишем поведение агента который случайно с добовлением seed шага выбирает любой элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seed_step_random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile seed_step_random_agent.py\n",
    "import random\n",
    "\n",
    "def seed_step_random_agent(observation, configuration):\n",
    "    random.seed(observation.step)\n",
    "    return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 Опишем поведение агента который случайно с добовлением seed времени выбирает любой элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seed_time_random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile seed_time_random_agent.py\n",
    "import random\n",
    "import time\n",
    "\n",
    "def seed_time_random_agent(observation, configuration):\n",
    "    random.seed(time.time())\n",
    "    result = random.randrange(0, configuration.signs)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Опишем поведение агента который случайно выберает через nampy random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nampy_random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nampy_random_agent.py\n",
    "import numpy as np\n",
    "\n",
    "def nampy_random_agent(observation, configuration):\n",
    "    return np.random.randint(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим турнир где все играют со всеми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nampy_random_agent.py', 14),\n",
       " ('rock_scissors_agent.py', 13),\n",
       " ('order_rock_scissors_paper_agent.py', 13),\n",
       " ('random_agent.py', 13),\n",
       " ('oposite_agent.py', 11),\n",
       " ('seed_time_random_agent.py', 11),\n",
       " ('shift_random_agent.py', 10),\n",
       " ('rock_paper_agent.py', 9),\n",
       " ('paper_agent.py', 8),\n",
       " ('shift_one_agent.py', 8),\n",
       " ('seed_step_random_agent.py', 7),\n",
       " ('scissors_agent.py', 6)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_list = [\n",
    "    \"scissors_agent.py\",\n",
    "    \"paper_agent.py\",\n",
    "    \"rock_scissors_agent.py\",\n",
    "    \"rock_paper_agent.py\",\n",
    "    \"order_rock_scissors_paper_agent.py\",\n",
    "    \"random_agent.py\",\n",
    "    \"oposite_agent.py\",\n",
    "    \"shift_one_agent.py\",\n",
    "    \"shift_random_agent.py\",\n",
    "    \"seed_step_random_agent.py\",\n",
    "    \"seed_time_random_agent.py\",\n",
    "    \"nampy_random_agent.py\"\n",
    "]\n",
    "\n",
    "result_score = {}\n",
    "\n",
    "for agent in agent_list:\n",
    "    result_score[agent] = 0\n",
    "\n",
    "for current_agent in agent_list:\n",
    "    for agent in agent_list:\n",
    "        if current_agent == agent:\n",
    "            continue\n",
    "        result = evaluate(\n",
    "                \"rps\",\n",
    "                agents = [current_agent, agent],\n",
    "                configuration = {\"episodeSteps\": 101, 'tieRewardThreshold': 1},\n",
    "                debug = False\n",
    "            )\n",
    "        if result[0][0] > result[0][1]:\n",
    "            result_score[current_agent] += 1\n",
    "        elif result[0][0] < result[0][1]:\n",
    "            result_score[agent] += 1\n",
    "sorted(result_score.items(), key=lambda kv: kv[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [[7.0, -7.0]]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    \"rps\", #environment to use - no need to change\n",
    "    [\"nampy_random_agent.py\", \"scissors_agent.py\"], #agents to evaluate\n",
    "    configuration={\"episodeSteps\": 101, 'tieRewardThreshold': 1}, #number of episodes,\n",
    "    debug = True\n",
    ")\n",
    "print(f\"result {result}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
